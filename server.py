"""
FastAPI app to serve public REST API to connect frontend clients to the core LLM engine

Usage: run with uvicorn, sharing SERVER_URL in .env for clients to use
"""
import os
import random
import re
import string
from pathlib import Path

import pandas as pd
from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

from asr import DecodeResult, DecodeConfig
from main import create_session, new_session, get_session_by_token, Session, ModelName

root_path = os.path.dirname(os.path.realpath(__file__))
# root_path = os.path.abspath(os.path.dirname(__file__))

env = os.environ.get('DATACHAT_ENV', 'development')
production = env == 'production'
if production:
    print('Running in production mode')

load_dotenv(dotenv_path=os.path.join(root_path, ".env.production") if production else None, override=True)

SERVER_URL = os.environ.get('SERVER_URL')
FRONTEND_URL = os.environ.get('FRONTEND_URL')

# SERVER_URL = 'https://dcapi.sonnguyen.online' if production else 'http://localhost:8000'
# FRONTEND_URL = 'https://datachat.sonnguyen.online' if production else 'http://localhost:5173'

api = FastAPI()

# CORS required for cross-domain client connection
# Restrict origins to minimum for security
api.add_middleware(
    CORSMiddleware,
    allow_origins=['*'],  # '[FRONTEND_URL],
    allow_credentials=True,
    allow_methods=['*'],
    allow_headers=['*'],
)

# Mount public folder, mainly for exposing images generated by the LLM engine
api.mount(
    '/public', StaticFiles(directory=os.path.join(root_path, 'public')), name='static'
)
api.mount(
    '/media', StaticFiles(directory=os.path.join(root_path, 'media')), name='media'
)

require_session = True


# @api.middleware("http")
# async def middleware(request: Request, call_next):
#     response: Response = await call_next(request)
#     print('Response', vars(response))
#     return response


@api.get('/')
def about():
    return {'app': "Son's Data Chat API App"}


class SessionResponse(BaseModel):
    token: str


@api.post('/session')
def create_api_session() -> SessionResponse:
    """Create new session

    Client should call this first before any further API calls

    Returns
    (json.token) Unique token to identify this session,
        which client should append as query param to every subsequent request
    """
    token = create_session()
    return SessionResponse(token=token)


def get_session(token) -> Session:
    """Internal function to get the session associated with calling client."""
    if not require_session:
        return new_session()
    session = get_session_by_token(token)
    if session is None:
        raise HTTPException(status_code=403, detail='Invalid session')
    return session


class SetModelResponse(BaseModel):
    model: str


@api.post('/model')
async def set_model(model: str, token: str) -> SetModelResponse:
    """Change current LLM model

    See corresponding session method for details.
    """
    session = get_session(token)
    session.set_model(ModelName.openai if model == 'openai' else ModelName.bamboo)
    print('Switched model to:', model)
    return SetModelResponse(model=model)


def generate_filename(extension: str) -> str:
    return (
            ''.join(random.choices(string.ascii_lowercase + string.digits, k=24))
            + '.'
            + extension
    )


class UploadResponse(BaseModel):
    rows: list[int]
    selectedIndex: int


class MediaUploadResponse(BaseModel):
    type: str
    url: str
    result: DecodeResult


class MediaDecodeResponse(BaseModel):
    result: DecodeResult


@api.post('/data/input')
async def upload_files(files: list[UploadFile], token: str) -> UploadResponse | MediaUploadResponse:
    """Upload files as data input

    Upload files, read data from files and set it as current dataset
    """
    session = get_session(token)
    rows = []
    dfs = []
    try:
        for file in files:
            extension = os.path.splitext(file.filename)[1][1:].lower()
            if extension not in ['csv', 'xlsx', 'mp3', 'wav', 'mp4', 'mpeg', 'webm']:
                raise HTTPException(
                    status_code=400, detail='Input file must be datasheet or media'
                )
            if extension not in ['csv', 'xlsx']:
                out_filename = generate_filename(extension)
                out_path = f'{root_path}/media/{out_filename}'
                with open(out_path, "wb+") as out_file:
                    # shutil.copyfileobj(file.file, out_file)
                    out_file.write(file.file.read())
                media = session.get_preprocess_response(file.filename, out_path)
                # result = session.get_transcribe_response(file.filename, out_path)
                # if result.info is not None and math.isinf(result.info.vad_options.max_speech_duration_s):
                #     result.info.vad_options.max_speech_duration_s = 0
                return MediaUploadResponse(
                    type=media.type, url=f'{SERVER_URL}/media/{out_filename}', result=media.result)

            df = (
                pd.read_csv(file.file)
                if extension == 'csv'
                else pd.read_excel(file.file)
            )
            dfs.append(df)
            rows.append(len(df.index))
        session.set_data(dfs)
        return UploadResponse(rows=rows, selectedIndex=0)
    except (IOError, Exception) as e:
        raise HTTPException(status_code=500, detail=repr(e))


class TranscribeResponse(BaseModel):
    result: object


@api.post('/transcribe')
async def get_transcribe(token: str, config: DecodeConfig) -> TranscribeResponse:
    print(config)
    session = get_session(token)
    try:
        media = session.get_transcribe_response(config)
        return TranscribeResponse(result=media.result)
    except (ValueError, Exception) as e:
        print('Transcribe error', e)
        raise HTTPException(status_code=500, detail=f'System error: {repr(e)}')


class SetDataResponse(BaseModel):
    selectedIndex: int


@api.post('/data/select')
async def select_data(index: int, head: int, token: str) -> SetDataResponse:
    """Change current data selection

    See corresponding session method for details.
    """
    session = get_session(token)
    session.select_data(index, head)
    return SetDataResponse(selectedIndex=index)


class QueryInput(BaseModel):
    query: str


class QueryResponse(BaseModel):
    answer: str
    type: str
    html: bool


def render_image(path):
    """Internal function to render image output from LLM as HTML img tag using the mounted URL."""
    file = Path(path)
    if file.is_file():
        public_url = f'{SERVER_URL}/public/{file.name}'
        return public_url


def render_answer(answer) -> (str, str):
    """Internal function to render answer output according to detected format."""
    t = type(answer)
    if t is str:
        if re.search(r'\.(png|jpe?g)$', answer, re.IGNORECASE):
            return str(
                f'<img src="{render_image(answer)}" alt="See image for answer">'
            ), 'html'
    elif t is pd.DataFrame:
        return answer.to_html(), 'html'
    return str(answer), 'text'


@api.post('/query')
async def post_query(query: QueryInput, token: str) -> QueryResponse:
    """Query current LLM model with user prompt

    See corresponding session method for details.
    """
    session = get_session(token)
    try:
        resp = session.get_chat_response(query.query)
        t = type(resp)
        answer, sformat = render_answer(resp)
        return QueryResponse(answer=answer, type=t.__name__, html=sformat == 'html')
    except (ValueError, Exception) as e:
        print('Query response error', e)
        raise HTTPException(status_code=500, detail=f'System error: {repr(e)}')
